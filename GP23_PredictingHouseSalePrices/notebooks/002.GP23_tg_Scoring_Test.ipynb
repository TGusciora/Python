{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Predicting house sale prices\n",
    "## Part 2: Test sample scoring and final model selection\n",
    "**Data:** housing data for the city of Ames, Iowa, USA, 2006 to 2010  \n",
    "**Data description:** https://s3.amazonaws.com/dq-content/307/data_description.txt  \n",
    "**Source:** https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627  \n",
    "**Source pdf:** https://www.tandfonline.com/doi/pdf/10.1080/10691898.2011.11889627?needAccess=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up auto-reload functions for faster debugging \n",
    "# (automatically refreshes changes in subpackages codes)\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import parent directory (main project directory)\n",
    "# for packages importing\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Getting the parent directory name in which your script is running\n",
    "parent = os.path.dirname(os.path.realpath(''))\n",
    "\n",
    "# adding the parent directory to\n",
    "# the sys.path.\n",
    "sys.path.append(parent)\n",
    "\n",
    "# now we can import the module in the parent\n",
    "# directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project packages import\n",
    "import gp23package.data.make_dataset as gp23md\n",
    "import gp23package.explore_visualise.eda as gp23eda\n",
    "import gp23package.features.build_features as gp23feat\n",
    "import gp23package.models.hyperparameters_model as gp23hyperparam\n",
    "import gp23package.models.train_model as gp23train\n",
    "# Pylance highligting package issue (not to be worried about)\n",
    "# https://github.com/microsoft/pylance-release/blob/main/TROUBLESHOOTING.md#unresolved-import-warnings\n",
    "\n",
    "# Standard Python libraries import\n",
    "from IPython.display import display, HTML #  tidied-up display\n",
    "from time import time #  project timer\n",
    "from itertools import chain # for list iterations\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_selection import (SelectKBest, chi2, f_regression, RFE, mutual_info_regression,\n",
    "                                      SequentialFeatureSelector, SelectFromModel)\n",
    "from sklearn.preprocessing import (normalize, MinMaxScaler)\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score)\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, KFold, GridSearchCV)\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, ElasticNet, Lasso, TheilSenRegressor, RANSACRegressor,\n",
    "                                  HuberRegressor , SGDRegressor, Lars, ElasticNet, RidgeCV)\n",
    "\n",
    "#statsmodels\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels as sm\n",
    "import statsmodels.stats.stattools as smt\n",
    "import statsmodels.stats.diagnostic as smd\n",
    "\n",
    "# Other\n",
    "from dython import nominal # Correlations between categorical variables\n",
    "\n",
    "# Necessary packages\n",
    "import gp23package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle # dump models\n",
    "\n",
    "#turning on plot display in JN\n",
    "%matplotlib inline \n",
    "# Setting pandas display options\n",
    "pd.options.display.max_columns = 300\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_colwidth = 250"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Importing models & data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading saved models and transformation objects\n",
    "filename = 'model_list.sav'\n",
    "file = os.path.join(parent, 'models', filename)\n",
    "with open(file, 'rb') as file_open:\n",
    "    test_model_list = pickle.load(file_open)\n",
    "\n",
    "filename = 'boxCox_dict.sav'\n",
    "file = os.path.join(parent, 'data\\processed', filename)\n",
    "with open(file, 'rb') as file_open:\n",
    "    test_boxCox_dict = pickle.load(file_open)\n",
    "\n",
    "filename = 'data_optbin.sav'\n",
    "file = os.path.join(parent, 'data\\processed', filename)\n",
    "with open(file, 'rb') as file_open:\n",
    "    test_data_optbin = pickle.load(file_open)\n",
    "\n",
    "filename = 'var_dict.sav'\n",
    "file = os.path.join(parent, 'data\\processed', filename)\n",
    "with open(file, 'rb') as file_open:\n",
    "    scoring_dict = pickle.load(file_open)\n",
    "\n",
    "# Loading test datasets\n",
    "filename = 'X_test.csv'\n",
    "file = os.path.join(parent, 'data\\interim', filename)\n",
    "X_test = pd.read_csv(file)\n",
    "\n",
    "filename = 'y_test.csv'\n",
    "file = os.path.join(parent, 'data\\interim', filename)\n",
    "y_test = pd.read_csv(file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Scoring new data - test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'variable_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m prefixes \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mWOE_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBox_\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[39m# taking all variable variations for final models\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfor\u001b[39;00m var \u001b[39min\u001b[39;00m test_model_list[\u001b[39m\"\u001b[39;49m\u001b[39mvariable_set\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39munique():\n\u001b[0;32m     17\u001b[0m     \u001b[39m# for each variable in variable set\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m scoring_dict[var]:\n\u001b[0;32m     19\u001b[0m         \u001b[39m# Removing prefixes from prefixes list\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         \u001b[39mfor\u001b[39;00m prefix \u001b[39min\u001b[39;00m prefixes:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'variable_set'"
     ]
    }
   ],
   "source": [
    "# MANUAL_INPUT\n",
    "# Scoring new vector of data\n",
    "# For this we need to have list of used variables for final models\n",
    "# If we have more than one model we would have to prepare more list concatenating all lists\n",
    "# Attention: for scoring we do need to use original variable list with exactly the same order of variables\n",
    "# In our current case var_dict[\"BKWD_20\"]\n",
    "\n",
    "scoring_vars = list(set(var_dict[\"BKWD_20\"] + var_dict[\"FWD_10\"]))\n",
    "\n",
    "\n",
    "scoring_varsRaw = []\n",
    "# List of prefixes differentiating engineered variables from original variables\n",
    "prefixes = [\"WOE_\", \"Box_\"]\n",
    "\n",
    "# taking all variable variations for final models\n",
    "for var in chosen_bestModels[\"variable_set\"].unique():\n",
    "    # for each variable in variable set\n",
    "    for i in var_dict[var]:\n",
    "        # Removing prefixes from prefixes list\n",
    "        for prefix in prefixes:\n",
    "            i = i.removeprefix(prefix)\n",
    "    # Adding raw variable name to scoring vars (if there are more than 1 variable lists there can be duplicates)\n",
    "        scoring_varsRaw.append(i)\n",
    "\n",
    "# Deduplicating variable names\n",
    "# Final list will probably come in different order than used source lists\n",
    "scoring_varsRaw = list(set(scoring_varsRaw))\n",
    "print('*** raw scoring_vars ***')\n",
    "print(scoring_varsRaw,'\\n')\n",
    "\n",
    "# Remark: in this project we divided data to train_valid / test samples after preliminary cleaning. In real-world cases\n",
    "# we will not have access to incoming data, hence all the preliminary data cleaning would have to be done on new data\n",
    "# as well. \n",
    "\n",
    "# Limiting number of input variables\n",
    "X_test = X_test[scoring_varsRaw]\n",
    "\n",
    "# Transforming y metric\n",
    "# we are not winsorizing test data outcome variable as this would lead to false fit metrics\n",
    "y2_test = np.log(y_test) \n",
    "\n",
    "# Creating empty subset of final scoring variavbles (engineered)\n",
    "scoringFinal_vars = list(set(scoring_varsRaw).intersection(discrete))\n",
    "print('*** discrete variables intersection ***')\n",
    "print(scoringFinal_vars,'\\n')\n",
    "print('*** Variables used for scoring ***')\n",
    "print(scoring_vars,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming input variables\n",
    "# WoE transformation for categorical variables (common values between categorical vars and scoring_vars)\n",
    "for i in set(categorical).intersection(scoring_varsRaw) :\n",
    "    X_test[\"WOE_\"+i] = var_transform(data = X_test, var_name = i, optbin_dict = data_optbin)   \n",
    "# Box-Cox power transformation for continuous variables (common values between continuous and scoring_vars)\n",
    "# We use lambdas from boxCox_dict dictionary (lambda values calculated on train_valid dataset). This is to prevent\n",
    "# Target information leakage between samples\n",
    "for i in set(continuous).intersection(scoring_varsRaw) :\n",
    "    X_test[\"Box_\"+i] = stats.boxcox(x = X_test[i]+1 , lmbda = boxCox_dict[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
